{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENESIS Level 0 Training\n",
    "\n",
    "Train the Level 0 (Machine Code Patterns) model using Google Colab's free GPU.\n",
    "\n",
    "## Setup\n",
    "1. Go to Runtime → Change runtime type → GPU (T4)\n",
    "2. Run all cells in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/YOUR_USERNAME/genesis.git\n",
    "%cd genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch transformers peft datasets accelerate capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset exists, generate if not\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"genesis_datasets/level0/train.jsonl\")\n",
    "if not dataset_path.exists():\n",
    "    print(\"Generating dataset...\")\n",
    "    from genesis_datasets.generators.level0_generator import Level0DatasetGenerator, get_system_binaries\n",
    "    \n",
    "    generator = Level0DatasetGenerator(seed=42)\n",
    "    samples = generator.generate_dataset(\n",
    "        synthetic_count=5000,\n",
    "        adversarial_count=1000,\n",
    "        binary_paths=get_system_binaries(),\n",
    "        binary_samples_per_file=100,\n",
    "    )\n",
    "    generator.save_dataset(samples, dataset_path)\n",
    "    print(f\"Generated {len(samples)} samples\")\n",
    "else:\n",
    "    print(f\"Dataset exists: {dataset_path}\")\n",
    "    !wc -l {dataset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training\n",
    "from core.training import TrainingConfig, ModelConfig\n",
    "\n",
    "config = TrainingConfig(\n",
    "    output_dir=Path(\"models/level0\"),\n",
    "    model=ModelConfig(\n",
    "        model_name=\"distilgpt2\",  # Small model, fast training\n",
    "        use_lora=True,\n",
    "        lora_r=8,\n",
    "        max_length=256,\n",
    "    ),\n",
    "    batch_size=8,\n",
    "    num_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {config.model.model_name}\")\n",
    "print(f\"  LoRA: r={config.model.lora_r}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "\n",
    "warnings = config.validate()\n",
    "for w in warnings:\n",
    "    print(f\"⚠️ {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "from core.training import train_level0\n",
    "\n",
    "metrics = train_level0(config, dataset_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Metrics: {metrics.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gate requirements\n",
    "passes, failures = metrics.meets_gate_requirements()\n",
    "\n",
    "if passes:\n",
    "    print(\"✅ Model PASSES gate requirements!\")\n",
    "    print(\"Level 0 is complete. Ready for Level 1.\")\n",
    "else:\n",
    "    print(\"❌ Model FAILS gate requirements:\")\n",
    "    for f in failures:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "!zip -r level0_model.zip models/level0/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('level0_model.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
